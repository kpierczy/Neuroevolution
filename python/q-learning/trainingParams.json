{
    "computeDevices": "-1",
    "environment": "Breakout-ram-v0",
    "paths": {
        "savesDir" : "python/q-learning/saves",
        "initialModelName" : false,
        "initialReplayMemoryName" : false
    },
    "time": {
        "maxFramesNum" : 500000,
        "maxFramesPerGame" : 1800,
        "learningFrequency" : 4,
        "evaluationFreq" : 10000 ,
        "evaluationGames" : 5
    },
    "agent": {
        "replayMemorySize" : 1000000,
        "initialReplayMemorySize" : 20000,
        "clipReward" : true,
        "trainingFrameKeep" : 3,
        "evaluationFrameKeep" : 1,
        "stackedStateLength" : 1,
        "epsilonPolicy" : "linear",
        "epsilonPolicyConfig": {
            "linear": {
                "initial" : 1,
                "initialPeriod" : 20000,
                "firstTarget" : 0.1,
                "firstTargetPeriod" : 180000,
                "finalTarget" : 0.01,
                "finalTargetPeriod" : 300000
            },
            "exponential": {
                "initial" : 1,
                "decay" : 0.0995
            }
        }
    },
    "model": {
        "optimizer" : "Adam",
        "lossFunction" : "mse",
        "learningRate" : 25e-5,
        "batchSize" : 32,
        "layers" : [
            {"type" : "flatten"},
            {"type" : "dennse", "units" : 128, "activation" : "relu", "initializer" : "varianceScaling", "scale" : 2},
            {"type" : "dennse", "units" : 128, "activation" : "relu", "initializer" : "varianceScaling", "scale" : 2}
        ],
        "name" : "DQN_Breakout_player"
    },
    "log":{
        "directory" : "python/q-learning/logs",
        "logID" : "run_1",
        "display" : true,
        "displayEval" : true,
        "meanTrainingScoreLength" : 100,
        "verboseLearning" : false,
        "trainingLogUpdateFreq" : 10
    }


}